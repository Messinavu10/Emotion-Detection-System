{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWvMKvxzev5t",
        "outputId": "d39d6e0a-de01-480c-b31d-3c306763beed"
      },
      "outputs": [],
      "source": [
        "! pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFA_TKK1e7wf",
        "outputId": "0b09cc7e-23b1-4eb8-cffb-7b00fca73cbd"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ta4Eau2RkyHz"
      },
      "outputs": [],
      "source": [
        "#dataset directory\n",
        "RAV = \"/content/drive/MyDrive/Colab Notebooks/SpeechData/audio-data/\"\n",
        "CREMA = \"/content/drive/MyDrive/Colab Notebooks/SpeechData/AudioWAV/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SKb5DgF6mJkZ"
      },
      "outputs": [],
      "source": [
        "#import the libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# librosa is a Python library for analyzing audio and music. It can be used to extract the data from the audio files we will see it later.\n",
        "import librosa\n",
        "import librosa.display\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# to play the audio files\n",
        "#from IPython.display import Audio\n",
        "import IPython.display as ipd\n",
        "\n",
        "import keras\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
        "#from keras.utils import np_utils, to_categorical\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "import warnings\n",
        "if not sys.warnoptions:\n",
        "    warnings.simplefilter(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "s549k3eEm3vZ",
        "outputId": "182b7b99-b30c-49f0-831f-66f06aaf55ef"
      },
      "outputs": [],
      "source": [
        "ravdess_directory_list = os.listdir(RAV)\n",
        "\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "for dir in ravdess_directory_list:\n",
        "    # as their are 20 different actors in our previous directory we need to extract files for each actor.\n",
        "    actor = os.listdir(RAV + dir)\n",
        "    for file in actor:\n",
        "        part = file.split('.')[0]\n",
        "        part = part.split('-')\n",
        "        # third part in each file represents the emotion associated to that file.\n",
        "        file_emotion.append(int(part[2]))\n",
        "        file_path.append(RAV + dir + '/' + file)\n",
        "\n",
        "# dataframe for emotion of files\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "\n",
        "# dataframe for path of files.\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "Ravdess_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "\n",
        "# changing integers to actual emotions.\n",
        "Ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
        "Ravdess_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1a9Izy5FqayD",
        "outputId": "a4c26710-53e3-4d04-8ac4-13bb09ac9d33"
      },
      "outputs": [],
      "source": [
        "crema_directory_list = os.listdir(CREMA)\n",
        "\n",
        "file_emotion = []\n",
        "file_path = []\n",
        "\n",
        "for file in crema_directory_list:\n",
        "    # storing file paths\n",
        "    file_path.append(CREMA + file)\n",
        "    # storing file emotions\n",
        "    part=file.split('_')\n",
        "    if part[2] == 'SAD':\n",
        "        file_emotion.append('sad')\n",
        "    elif part[2] == 'ANG':\n",
        "        file_emotion.append('angry')\n",
        "    elif part[2] == 'DIS':\n",
        "        file_emotion.append('disgust')\n",
        "    elif part[2] == 'FEA':\n",
        "        file_emotion.append('fear')\n",
        "    elif part[2] == 'HAP':\n",
        "        file_emotion.append('happy')\n",
        "    elif part[2] == 'NEU':\n",
        "        file_emotion.append('neutral')\n",
        "    else:\n",
        "        file_emotion.append('Unknown')\n",
        "\n",
        "# dataframe for emotion of files\n",
        "emotion_df = pd.DataFrame(file_emotion, columns=['Emotions'])\n",
        "\n",
        "# dataframe for path of files.\n",
        "path_df = pd.DataFrame(file_path, columns=['Path'])\n",
        "Crema_df = pd.concat([emotion_df, path_df], axis=1)\n",
        "Crema_df.head()\n",
        "print(Crema_df.Emotions.value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "L-PIJD-FocJu",
        "outputId": "6b9a6fa6-f508-46e3-b44b-65db1243fa74"
      },
      "outputs": [],
      "source": [
        "#Pick a fearful track\n",
        "\n",
        "##need to verify spectogram for visualization###\n",
        "\n",
        "fname = RAV + 'Actor_14/03-01-06-02-02-02-14.wav'\n",
        "data, sampling_rate = librosa.load(fname)\n",
        "plt.figure(figsize=(15, 5))\n",
        "librosa.display.waveshow(data, sr=sampling_rate)\n",
        "# Lets play the audio\n",
        "ipd.Audio(fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qyOYVY88tiHv",
        "outputId": "6465a99e-3ecb-4f77-ab16-fbc1b1c9cfd6"
      },
      "outputs": [],
      "source": [
        "plt.specgram(data, Fs=sampling_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 514
        },
        "id": "DLbZ0A8Cqvei",
        "outputId": "f0dd7655-aa46-4a1c-8abb-790b1a268d46"
      },
      "outputs": [],
      "source": [
        "# Pick a happy track\n",
        "\n",
        "###need to verify spectogram for visualization###\n",
        "\n",
        "fname = RAV + 'Actor_14/03-01-03-02-02-02-14.wav'\n",
        "data, sampling_rate = librosa.load(fname)\n",
        "plt.figure(figsize=(15, 5))\n",
        "librosa.display.waveshow(data, sr=sampling_rate)\n",
        "\n",
        "# Lets play the audio\n",
        "ipd.Audio(fname)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "p-1phfs9wmWC",
        "outputId": "c96ebefa-fd77-43cb-edcf-bef42a5b948b"
      },
      "outputs": [],
      "source": [
        "    # Plot MFCCs\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.specshow(librosa.feature.mfcc(y=data, sr=sampling_rate, n_mfcc=13), x_axis='time', cmap='viridis')\n",
        "    plt.colorbar(format='%+2.0f dB')\n",
        "    plt.title('MFCC')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('MFCC Coefficient')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oVtTAWs9rFfD",
        "outputId": "380c2140-790d-4ab0-a277-e843816aa3d6"
      },
      "outputs": [],
      "source": [
        "plt.specgram(data, Fs=sampling_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "_ACeCUcIIFVt",
        "outputId": "ab49da37-e093-41af-f83b-d8a89a90b044"
      },
      "outputs": [],
      "source": [
        "#dataframe for the two datasets\n",
        "data_path = pd.concat([Ravdess_df, Crema_df], axis = 0)\n",
        "data_path.to_csv(\"data_path.csv\",index=False)\n",
        "data_path.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3l8oHwViqHD"
      },
      "outputs": [],
      "source": [
        "def noise(data):\n",
        "    noise_amp = 0.035*np.random.uniform()*np.amax(data)\n",
        "    data = data + noise_amp*np.random.normal(size=data.shape[0])\n",
        "    return data\n",
        "\n",
        "def stretch(data, rate=0.8):\n",
        "    return librosa.effects.time_stretch(data, rate=rate)\n",
        "\n",
        "def pitch(data, sampling_rate, pitch_factor=0.7):\n",
        "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor=pitch_factor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPZ1rWhFxktE"
      },
      "outputs": [],
      "source": [
        "def extract_features(data):\n",
        "\n",
        "  result = np.array([])\n",
        "\n",
        "  # ZCR\n",
        "  zcr = np.mean(librosa.feature.zero_crossing_rate(y=data).T, axis=0)\n",
        "  result=np.hstack((result, zcr)) # stacking horizontally\n",
        "\n",
        "  # MFCC\n",
        "  mfcc = np.mean(librosa.feature.mfcc(y=data, sr=sampling_rate).T, axis=0)\n",
        "  result = np.hstack((result, mfcc)) # stacking horizontally\n",
        "\n",
        "  # MelSpectogram\n",
        "  mel = np.mean(librosa.feature.melspectrogram(y=data, sr=sampling_rate).T, axis=0)\n",
        "  result = np.hstack((result, mel)) # stacking horizontally\n",
        "\n",
        "  # Root Mean Square Value\n",
        "  rms = np.mean(librosa.feature.rms(y=data).T, axis=0)\n",
        "  result = np.hstack((result, rms)) # stacking horizontally\n",
        "\n",
        "  return result\n",
        "\n",
        "def get_features(path):\n",
        "    # duration and offset are used to take care of the no audio in start and the ending of each audio files as seen above.\n",
        "  data, sampling_rate = librosa.load(path, duration=2.5, offset=0.6)\n",
        "\n",
        "    # without augmentation\n",
        "  res1 = extract_features(data)\n",
        "  result = np.array(res1)\n",
        "\n",
        "    # data with noise\n",
        "  noise_data = noise(data)\n",
        "  res2 = extract_features(noise_data)\n",
        "  result = np.vstack((result, res2)) # stacking vertically\n",
        "\n",
        "\n",
        "  #   #data with pitch\n",
        "  pitch_data = pitch(data,sampling_rate)\n",
        "  res3 = extract_features(pitch_data)\n",
        "  result = np.vstack((result, res3))\n",
        "\n",
        "  return result\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r72e1gMy6itO",
        "outputId": "efabc18a-101c-4ac0-a454-d7b83f78c7c4"
      },
      "outputs": [],
      "source": [
        "librosa.feature.melspectrogram(y=data, sr=sampling_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5GhgurHzAuA"
      },
      "outputs": [],
      "source": [
        "X, Y = [], []\n",
        "for path, emotion in zip(data_path.Path, data_path.Emotions):\n",
        "    feature = get_features(path)\n",
        "    for ele in feature:\n",
        "        X.append(ele)\n",
        "        # appending emotion 2 times as we have made 2 augmentation techniques on each audio file.\n",
        "        Y.append(emotion)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NFIXnaAzLqk",
        "outputId": "e3898636-2741-4704-e2e5-e3e4f9c8f91e"
      },
      "outputs": [],
      "source": [
        "\n",
        "len(X), len(Y), data_path.Path.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "TLc1MyVUEgWL",
        "outputId": "6e1898f3-9f7b-4d22-d279-b98915131f85"
      },
      "outputs": [],
      "source": [
        "Features = pd.DataFrame(X)\n",
        "Features['labels'] = Y\n",
        "Features.to_csv('features.csv', index=False)\n",
        "Features.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXrlh0r9F6F8"
      },
      "outputs": [],
      "source": [
        "#Normalize and splitting data\n",
        "X = Features.iloc[: ,:-1].values\n",
        "Y = Features['labels'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyWOKCGiGIPG"
      },
      "outputs": [],
      "source": [
        "encoder = OneHotEncoder()\n",
        "Y = encoder.fit_transform(np.array(Y).reshape(-1,1)).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qrfsv-S2GIKG",
        "outputId": "b4b6506d-43ef-44f0-947a-cf61dbc5f40a"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, random_state=35, test_size=0.2, shuffle=True)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vQhhtQ_rGIEE",
        "outputId": "3f20dd34-e8b0-4464-cb38-6c9e9f131a85"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "x_train = scaler.fit_transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wquTTkfGH-d",
        "outputId": "240ba3b6-150d-4ffa-ac7c-dcc6260a58eb"
      },
      "outputs": [],
      "source": [
        "# making our data compatible to model.\n",
        "x_train = np.expand_dims(x_train, axis=2)\n",
        "x_test = np.expand_dims(x_test, axis=2)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ck72iwTaYERL"
      },
      "outputs": [],
      "source": [
        "model_checkpoint = ModelCheckpoint('best_model1_weights.h5', monitor='val_accuracy', save_best_only=True)\n",
        "early_stop=EarlyStopping(monitor='val_acc',mode='auto',patience=5,restore_best_weights=True)\n",
        "lr_reduction=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,min_lr=0.00001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8eBPEh4GH2Y",
        "outputId": "50eeb622-aa9e-43ee-ee63-159d670764f6"
      },
      "outputs": [],
      "source": [
        "#Model\n",
        "model = tf.keras.Sequential([\n",
        "    L.Conv1D(512,kernel_size=5, strides=1,padding='same', activation='relu',input_shape=(x_train.shape[1],1)),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
        "\n",
        "    L.Conv1D(512,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
        "    Dropout(0.2),  # Add dropout layer after the second max pooling layer\n",
        "\n",
        "    L.Conv1D(256,kernel_size=5,strides=1,padding='same',activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
        "\n",
        "    L.Conv1D(256,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=5,strides=2,padding='same'),\n",
        "    Dropout(0.2),  # Add dropout layer after the fourth max pooling layer\n",
        "\n",
        "    L.Conv1D(128,kernel_size=3,strides=1,padding='same',activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.MaxPool1D(pool_size=3,strides=2,padding='same'),\n",
        "    Dropout(0.2),  # Add dropout layer after the fifth max pooling layer\n",
        "\n",
        "    L.Flatten(),\n",
        "    L.Dense(512,activation='relu'),\n",
        "    L.BatchNormalization(),\n",
        "    L.Dense(8,activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics='accuracy')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9iK68GfGHtl",
        "outputId": "803e2cb0-4964-4255-eb18-0ce4bb26deda"
      },
      "outputs": [],
      "source": [
        "#rlrp = ReduceLROnPlateau(monitor='loss', factor=0.4, verbose=0, patience=2, min_lr=0.0000001)\n",
        "#rlrp=ReduceLROnPlateau(monitor='val_acc',patience=3,verbose=1,factor=0.5,min_lr=0.00001)\n",
        "history=model.fit(x_train, y_train,epochs=30, validation_data=(x_test, y_test),batch_size=64, callbacks=[early_stop,lr_reduction,model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 392
        },
        "id": "JBpAxFjnPM2H",
        "outputId": "bd29bb1f-c88e-4fd3-9623-6ae05aba2c40"
      },
      "outputs": [],
      "source": [
        "#training performance\n",
        "train_accuracy=model.fit(x_train, x_test,epochs=30, validation_data=(x_train, x_test),batch_size=64, callbacks=[early_stop,lr_reduction,model_checkpoint])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "eER6lg0-gCg0",
        "outputId": "e3c6b962-d21c-4b55-8d7e-9fa5f7a07cb7"
      },
      "outputs": [],
      "source": [
        "print(\"Accuracy of our model on test data : \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")\n",
        "\n",
        "epochs = [i for i in range(30)]\n",
        "fig , ax = plt.subplots(1,2)\n",
        "train_acc = history.history['accuracy']\n",
        "train_loss = history.history['loss']\n",
        "test_acc = history.history['val_accuracy']\n",
        "test_loss = history.history['val_loss']\n",
        "\n",
        "fig.set_size_inches(20,6)\n",
        "ax[0].plot(epochs , train_loss , label = 'Training Loss')\n",
        "ax[0].plot(epochs , test_loss , label = 'Testing Loss')\n",
        "ax[0].set_title('Training & Testing Loss')\n",
        "ax[0].legend()\n",
        "ax[0].set_xlabel(\"Epochs\")\n",
        "\n",
        "ax[1].plot(epochs , train_acc , label = 'Training Accuracy')\n",
        "ax[1].plot(epochs , test_acc , label = 'Testing Accuracy')\n",
        "ax[1].set_title('Training & Testing Accuracy')\n",
        "ax[1].legend()\n",
        "ax[1].set_xlabel(\"Epochs\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5lXDxWxg9tA",
        "outputId": "f2eae21e-66a6-425b-c194-b96abb210f92"
      },
      "outputs": [],
      "source": [
        "# predicting on test data.\n",
        "pred_test = model.predict(x_test)\n",
        "y_pred = encoder.inverse_transform(pred_test)\n",
        "\n",
        "y_test = encoder.inverse_transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzroa4BigFDW"
      },
      "outputs": [],
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize = (12, 10))\n",
        "cm = pd.DataFrame(cm , index = [i for i in encoder.categories_] , columns = [i for i in encoder.categories_])\n",
        "sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n",
        "plt.title('Confusion Matrix', size=20)\n",
        "plt.xlabel('Predicted Labels', size=14)\n",
        "plt.ylabel('Actual Labels', size=14)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
